# ğŸ§  Qwen2.5-7B â†’ Qwen1.8B çŸ¥è¯†è’¸é¦å®éªŒ (fdistill æ¡†æ¶)

æœ¬é¡¹ç›®å±•ç¤ºå¦‚ä½•ä½¿ç”¨ [MANGA-UOFA/fdistill](https://github.com/MANGA-UOFA/fdistill) æ¡†æ¶  
å°†ç»è¿‡ **GRPO å¾®è°ƒçš„ Qwen2.5-7B + LoRA** è’¸é¦ä¸ºæ›´è½»é‡çš„ **Qwen1.8B Student** æ¨¡å‹ã€‚  
æµç¨‹é’ˆå¯¹å•å¡ **A100-40GB** ç¯å¢ƒä¼˜åŒ–ï¼ŒåŒ…å«æ•°æ®æ··åˆã€Teacher è¾“å‡ºç”Ÿæˆä¸åœ¨çº¿è’¸é¦è®­ç»ƒã€‚

---

## ğŸ“¦ 1. ç¯å¢ƒå‡†å¤‡

```bash
conda create -n qwen_kd python=3.10 -y
conda activate qwen_kd
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.43.3 peft accelerate datasets bitsandbytes
pip install sentencepiece tqdm nlg-eval
```

---

## ğŸ“‚ 2. è·å– fdistill ä»“åº“

```bash
git clone https://github.com/MANGA-UOFA/fdistill.git
cd fdistill
```

---

## ğŸ§° 3. æ•°æ®å‡†å¤‡ï¼ˆ70% GRPO + 30% SFTï¼‰

ä»“åº“å†…çš„åŸå§‹æ•°æ®å·²ç»æŒ‰å…¬å¸ç±»åˆ«æ‹†åˆ†å­˜æ”¾ï¼š

- GRPOï¼š`artifacts/grpo/grpo_<category>.jsonl`
- SFTï¼š`artifacts/sft/sft_train_<category>.jsonl`
- `<category>` å–å€¼ï¼š`banks`ã€`households`ã€`insurance_companies`ã€`investment_advisors`ã€`mutual_funds`ã€`other`ã€`pension_funds`

è¿è¡Œä¸‹åˆ—è„šæœ¬ï¼Œå°†æ¯ä¸ªå…¬å¸ç±»åˆ«æŒ‰ 70% GRPO + 30% SFT æ··åˆï¼Œè¾“å‡ºåˆ° `artifacts/distill_data/raw/train_mix_<category>.jsonl`ï¼š

```bash
python - <<'PY'
import json
import random
from pathlib import Path

repo_root = Path.cwd()
grpo_dir = repo_root / "artifacts" / "grpo"
sft_dir = repo_root / "artifacts" / "sft"
output_dir = repo_root / "artifacts" / "distill_data" / "raw"
output_dir.mkdir(parents=True, exist_ok=True)

categories = [
    "banks",
    "households",
    "insurance_companies",
    "investment_advisors",
    "mutual_funds",
    "other",
    "pension_funds",
]

def load_jsonl(path: Path):
    with path.open("r", encoding="utf-8") as f:
        return [json.loads(line) for line in f if line.strip()]

random.seed(42)
for cat in categories:
    grpo_path = grpo_dir / f"grpo_{cat}.jsonl"
    sft_path = sft_dir / f"sft_train_{cat}.jsonl"

    if not grpo_path.exists() or not sft_path.exists():
        print(f"[skip] {cat}: missing source file")
        continue

    grpo_records = load_jsonl(grpo_path)
    sft_records = load_jsonl(sft_path)
    if not grpo_records or not sft_records:
        raise RuntimeError(f"{cat}: empty source data")

    grpo_take = min(int(len(grpo_records) * 0.7), len(grpo_records))
    sft_take = min(int(len(sft_records) * 0.3), len(sft_records))

    mix = random.sample(grpo_records, grpo_take) + random.sample(sft_records, sft_take)
    random.shuffle(mix)

    out_path = output_dir / f"train_mix_{cat}.jsonl"
    with out_path.open("w", encoding="utf-8") as f:
        for rec in mix:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

    print(f"[ok] {cat}: {len(mix)} records -> {out_path}")
PY
```

è„šæœ¬æ‰§è¡Œå®Œåï¼Œ`artifacts/distill_data/raw/` ä¸‹å°†ç”Ÿæˆå„å…¬å¸çš„ `train_mix_<category>.jsonl`ï¼Œåç»­æ­¥éª¤ä¼šåŸºäºè¿™äº›æ–‡ä»¶ç”Ÿæˆæ•™å¸ˆä¼ªæ ‡ç­¾å¹¶è½¬æˆæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„ `.source/.target` æ ¼å¼ã€‚

---

## ğŸ§  4. ç”Ÿæˆ Teacher è¾“å‡ºï¼ˆç¦»çº¿ä¼ªæ ‡ç­¾ï¼‰

1. **å¯¼å‡º Prompt**  
   ```bash
   python scripts/export_infer_prompts.py \
     --in artifacts/distill_data/raw/train_mix_banks.jsonl \
     --out-dir artifacts/distill_data/raw \
     --stem banks_teacher
   ```
   `banks` æ¢æˆå…¶å®ƒå…¬å¸å³å¯ã€‚è„šæœ¬ä¼šç”Ÿæˆ `banks_teacher_prompts_base.jsonl`ï¼ˆä¸ `_grpo` å†…å®¹ç›¸åŒï¼Œä¿ç•™ä¸€ä»½å³å¯ï¼‰ã€‚

2. **æ‰¹é‡æ¨ç†**  
   ```bash
   python scripts/batch_infer.py \
     --jsonl artifacts/distill_data/raw/banks_teacher_prompts_base.jsonl \
     --base_model Qwen/Qwen2.5-7B-Instruct \
     --checkpoint outputs/grpo_banks_qwen2p5/v3-20251103-130248/checkpoint-500 \
     --out_jsonl artifacts/distill_data/raw/teacher_outputs_banks.jsonl \
     --batch_size 4 \
     --max_new_tokens 512 \
     --temperature 0.7 \
     --torch_dtype bfloat16
   ```
   - `--base_model` å¯æ¢æˆæœ¬åœ°ç¼“å­˜ç›®å½•ã€‚
   - ç”Ÿæˆçš„ `teacher_outputs_<category>.jsonl` åŒ…å«å®Œæ•´ `<think>/<answer>` æ–‡æœ¬ä»¥åŠè§£æå‡ºçš„ `holding_log_delta`ã€‚

3. **è½¬æ¢ä¸º `.source/.target`**  
   ```bash
   python - <<'PY'
   import json
   from pathlib import Path

   root = Path("artifacts/distill_data")
   raw_dir = root / "raw"
   processed_dir = root / "processed"
   processed_dir.mkdir(parents=True, exist_ok=True)

   categories = [
       "banks",
       "households",
       "insurance_companies",
       "investment_advisors",
       "mutual_funds",
       "other",
       "pension_funds",
   ]

   for cat in categories:
       prompt_path = raw_dir / f"{cat}_teacher_prompts_base.jsonl"
       output_path = raw_dir / f"teacher_outputs_{cat}.jsonl"
       if not prompt_path.exists() or not output_path.exists():
           print(f"[skip] {cat}: missing prompts or teacher outputs")
           continue

       prompts = {}
       with prompt_path.open("r", encoding="utf-8") as f:
           for line in f:
               rec = json.loads(line)
               prompts[rec["id"]] = rec

       generations = []
       with output_path.open("r", encoding="utf-8") as f:
           for line in f:
               generations.append(json.loads(line))

       out_dir = processed_dir / cat
       out_dir.mkdir(parents=True, exist_ok=True)

       with (out_dir / "train.source").open("w", encoding="utf-8") as f_src, \
            (out_dir / "train.target").open("w", encoding="utf-8") as f_tgt:
           for row in sorted(generations, key=lambda x: x["id"]):
               prompt = prompts[row["id"]]
               system = (prompt.get("system") or "").strip()
               user = (prompt.get("prompt") or "").strip()
               teacher = (row.get("raw_output") or "").rstrip()
               f_src.write(f"{system}\n\n{user}\n")
               f_tgt.write(f"{teacher}\n")

       print(f"[ok] wrote {cat}: {len(generations)} samples -> {out_dir}")
   PY
   ```

æœ€ç»ˆï¼Œè’¸é¦è„šæœ¬çš„ `--data_dir` å¯ä»¥ç›´æ¥æŒ‡å‘ `artifacts/distill_data/processed/<category>`ï¼Œå…¶ä¸­åŒ…å« `train.source` / `train.target`ï¼ˆä»¥åŠæŒ‰éœ€æ‰©å±•çš„ `val.*`ã€`test.*`ï¼‰ã€‚

---

## ğŸ”¥ 5. å¯åŠ¨è’¸é¦è®­ç»ƒ (KL Divergence)

```bash
cat > run_qwen_kd.sh <<'SH'
#!/bin/bash
export CUDA_VISIBLE_DEVICES=0

python train_kd.py \
  --teacher_model "<base model path>" \
  --teacher_lora "<checkpoint path>" \
  --student_model "Qwen1.8B" \
  --dataset_path "data/mixed/teacher_outputs.json" \
  --output_dir "./output/student_kd" \
  --temperature 2.0 \
  --alpha 0.5 \
  --num_train_epochs 3 \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --lr 5e-5 \
  --fp16 True \
  --teacher_8bit True \
  --gradient_checkpointing True
SH

bash run_qwen_kd.sh
```

### å‚æ•°è¯´æ˜
| å‚æ•° | å«ä¹‰ | æ¨èå€¼ |
|------|------|--------|
| `temperature` | KL Soft label å¹³æ»‘åº¦ | 2.0 |
| `alpha` | KL ä¸ CE æƒé‡ | 0.5 |
| `batch_size` | å•å¡ batch | 2 |
| `gradient_accumulation_steps` | ç´¯ç§¯æ­¥æ•° | 8 |
| `lr` | å­¦ä¹ ç‡ | 5e-5 |
| `num_train_epochs` | è®­ç»ƒè½®æ•° | 3 |

é¢„è®¡æ˜¾å­˜å ç”¨ï¼š**çº¦ 36â€“38 GB (fp16)**ã€‚

---

## ğŸ“ˆ 6. æ¨¡å‹è¯„ä¼°ä¸è°ƒè¯•

### 6.1 æ„å»º Chat è¯„æµ‹é›†
`debug_eval_outputs.py` è¦æ±‚è¾“å…¥ä¸º chat æ ¼å¼ã€‚è‹¥æ‰‹ä¸Šåªæœ‰ prompt/teacher è¾“å‡ºï¼Œå¯å…ˆæ‹¼æˆ `messages` ç»“æ„ï¼š

```bash
PYTHONPATH=/workspace/rl-dbap python - <<'PY'
import json
from pathlib import Path

root = Path("artifacts/distill_data")
prompt_path = root / "raw" / "test_prompts_banks.jsonl"
teacher_path = root / "raw" / "teacher_outputs_banks.jsonl"
out_path = root / "processed" / "test_banks_chat.jsonl"

prompts = {}
with prompt_path.open() as f:
    for line in f:
        rec = json.loads(line)
        prompts[rec["id"]] = rec

rows = []
with teacher_path.open() as f:
    for line in f:
        rec = json.loads(line)
        prompt = prompts.get(rec["id"])
        if not prompt:
            continue
        system = prompt.get("system", "")
        user = prompt.get("prompt", "")
        raw = (rec.get("raw_output") or "").strip()
        think = (rec.get("think") or "").strip()
        answer = (rec.get("answer") or raw).strip()
        assistant_msgs = []
        if think:
            if not think.lower().startswith("<think>"):
                think = f"<think>{think}</think>"
            assistant_msgs.append({"role": "assistant", "content": think, "loss": False})
        if not answer.lower().startswith("<answer>"):
            answer = f"<answer>{answer}</answer>"
        assistant_msgs.append({"role": "assistant", "content": answer, "loss": True})
        rows.append({
            "id": rec["id"],
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
                *assistant_msgs,
            ],
        })

out_path.parent.mkdir(parents=True, exist_ok=True)
with out_path.open("w", encoding="utf-8") as f:
    for row in rows:
        f.write(json.dumps(row, ensure_ascii=False) + "\n")

print(f"[ok] wrote {len(rows)} rows -> {out_path}")
PY
```

ä¸ºå…¶å®ƒç±»åˆ«æ›¿æ¢ç›¸åº”çš„ `test_prompts_*.jsonl` ä¸ `teacher_outputs_*.jsonl` å³å¯ã€‚

### 6.2 è·‘æ¨ç†ï¼ˆStudent / Baseline / Teacherï¼‰

ä»¥ä¸‹å‘½ä»¤é»˜è®¤åœ¨ `/workspace/rl-dbap` ç›®å½•æ‰§è¡Œï¼Œå¯æŒ‰éœ€è°ƒæ•´ batch sizeï¼š

```bash
# Student (è’¸é¦åæ¨¡å‹)
PYTHONPATH=/workspace/rl-dbap python scripts/debug_eval_outputs.py \
  --test-path artifacts/distill_data/processed/test_banks_chat.jsonl \
  --base-model /workspace/rl-dbap/outputs/student_seqkd_1p5b/best_tfmr \
  --out-csv outputs/debug_eval_student_seqkd.csv \
  --batch-size 4 --max-new-tokens 128 --torch-dtype bfloat16

# Qwen2.5-1.5B åŸå§‹åŸºåº§
PYTHONPATH=/workspace/rl-dbap python scripts/debug_eval_outputs.py \
  --test-path artifacts/distill_data/processed/test_banks_chat.jsonl \
  --base-model /workspace/models/Qwen2.5-1.5B-Instruct \
  --out-csv outputs/debug_eval_qwen15b_base.csv \
  --batch-size 4 --max-new-tokens 128 --torch-dtype bfloat16

# Qwen2.5-7B åŸºåº§ï¼ˆå‚è€ƒä¸Šé™ï¼‰
PYTHONPATH=/workspace/rl-dbap python scripts/debug_eval_outputs.py \
  --test-path artifacts/distill_data/processed/test_banks_chat.jsonl \
  --base-model /workspace/models/Qwen2.5-7B-Instruct \
  --out-csv outputs/debug_eval_qwen7b_base.csv \
  --batch-size 2 --max-new-tokens 128 --torch-dtype bfloat16

# GRPO Teacherï¼ˆLoRA å½¢å¼ï¼‰
PYTHONPATH=/workspace/rl-dbap python scripts/debug_eval_outputs.py \
  --test-path artifacts/distill_data/processed/test_banks_chat.jsonl \
  --base-model /workspace/models/Qwen2.5-7B-Instruct \
  --lora-path /workspace/rl-dbap/outputs/grpo_banks_qwen2p5/v3-20251103-130248/checkpoint-500 \
  --out-csv outputs/debug_eval_grpo_qwen7b.csv \
  --batch-size 2 --max-new-tokens 128 --torch-dtype bfloat16
```

å¯åŠ ä¸Š `--limit 50` å¿«é€Ÿ sanity checkï¼Œå†ç§»é™¤è·‘å…¨é‡ã€‚

### 6.3 è¿‡æ»¤ä¸åˆè§„æ ·æœ¬ï¼ˆå¯é€‰ï¼‰
`compute_metrics_from_debug.py` å·²å†…ç½®è¿‡æ»¤é€»è¾‘ï¼›è‹¥æƒ³æå‰ç”Ÿæˆè¿‡æ»¤åçš„ CSV ä»¥ä¾¿äººå·¥æ’æŸ¥ï¼Œå¯è¿è¡Œï¼š

```bash
PYTHONPATH=/workspace/rl-dbap python - <<'PY'
import pandas as pd
from pathlib import Path
for name in ["student_seqkd", "qwen15b_base", "qwen7b_base", "grpo_qwen7b"]:
    path = Path(f"outputs/debug_eval_{name}.csv")
    if not path.exists():
        continue
    df = pd.read_csv(path)
    filt = df["raw_output"].astype(str).str.contains("holding_log_delta", case=False, na=False)
    out = path.with_name(path.stem + "_filtered.csv")
    df[filt].to_csv(out, index=False)
    print(f"[{name}] coverage = {filt.mean():.4f} ({filt.sum()}/{len(df)} rows) -> {out}")
PY
```

### 6.4 è®¡ç®—è¯„æµ‹æŒ‡æ ‡

[`scripts/compute_metrics_from_debug.py`](scripts/compute_metrics_from_debug.py) åœ¨å†…éƒ¨ä¼šå…ˆè¿‡æ»¤æ‰ `raw_output` ä¸­æœªåŒ…å« `holding_log_delta` çš„æ ·æœ¬ï¼Œå†è®¡ç®—ä¸ `run_eval` ä¸€è‡´çš„æŒ‡æ ‡ã€‚æ¨èå¯¹å››å¥—æ¨¡å‹ç»Ÿä¸€æŒ‰ 99% åˆ†ä½è£å‰ªè¯¯å·®ï¼š

```bash
export PYTHONPATH=/workspace/rl-dbap

for name in student_seqkd qwen15b_base qwen7b_base grpo_qwen7b; do
  python scripts/compute_metrics_from_debug.py \
    --debug-csv /workspace/rl-dbap/outputs/debug_eval_${name}.csv \
    --out-csv   /workspace/rl-dbap/outputs/metrics_${name}_q99.csv \
    --error-quantile 0.99
done
```

è‹¥æƒ³æŸ¥çœ‹â€œå…¨æ ·æœ¬â€è¡¨ç°ï¼Œå¯çœç•¥ `--error-quantile` å¹¶å¦å­˜ä¸€ä»½ï¼Œä¾‹å¦‚ `metrics_${name}_full.csv`ã€‚å¦‚éœ€å®Œå…¨å…³é—­è¿‡æ»¤ï¼Œå¯æ˜¾å¼ä¼ å…¥ `--filter-substring ''`ã€‚

### 6.5 æŒ‡æ ‡è§£è¯»å»ºè®®

- **coverage_filtered%**ï¼šè¿‡æ»¤åä»ä¿ç•™çš„æ ·æœ¬æ¯”ä¾‹ï¼Œå¯è§†ä½œæ¨¡å‹éµå®ˆè¾“å‡ºåˆåŒçš„åˆè§„ç‡ã€‚  
- **coverage_valid%**ï¼šåœ¨è¿‡æ»¤ç»“æœä¸Šèƒ½æˆåŠŸè§£æä¸ºæ•°å­—çš„å æ¯”ã€‚  
- **MAE/RMSEï¼ˆlog & tp1ï¼‰**ï¼šç”¨äºè¡¡é‡è¯¯å·®æ°´å¹³ï¼Œæ¨èå¯¹æ¯” `metrics_*_q99.csv` ç»“æœã€‚  
- **IC / RankIC / Topâ€‘K**ï¼šè¡¡é‡æ’åºç›¸å…³æ€§ä¸æŠ•èµ„å†³ç­–æŒ‡æ ‡ï¼Œéœ€ç»“åˆè¯¯å·®ä¸€èµ·è§‚å¯Ÿã€‚  
- **å…¨æ ·æœ¬ vs. åˆ†ä½è£å‰ª**ï¼šå…¨æ ·æœ¬ç»Ÿè®¡æœ‰åŠ©äºå‘ç°æç«¯å¼‚å¸¸ï¼ˆæœªåˆè§„ã€è¯¯è§£æç­‰ï¼‰ï¼Œè€Œ 0.99 åˆ†ä½æä¾›ç›¸å¯¹ç¨³å¥çš„æ¨¡å‹å¯¹æ¯”ã€‚

å®è·µä¸­ï¼ŒGRPO Teacher ä¸ Studentï¼ˆè’¸é¦æ¨¡å‹ï¼‰åœ¨åˆè§„è¦†ç›–ç‡ä¸è¯¯å·®ä¸Šæœ€æ¥è¿‘ï¼›åŸå§‹ 7B åŸºåº§æ¬¡ä¹‹ï¼›1.5B åŸºåº§åœ¨æœªå¯¹é½æƒ…å†µä¸‹åˆè§„ç‡ä¸è¯¯å·®éƒ½ä¼šæ˜æ˜¾åŠ£åŒ–ã€‚

---

## ğŸ’¾ 7. æ˜¾å­˜å ç”¨å‚è€ƒ (A100-40GB)

| æ¨¡å¼ | è¯´æ˜ | æ˜¾å­˜ | å¤‡æ³¨ |
|------|------|------|------|
| ç”Ÿæˆä¼ªæ ‡ç­¾ | ä»… Teacher (8bit) | ~18 GB | ç¦»çº¿ç”Ÿæˆ |
| åœ¨çº¿è’¸é¦ | Teacher + Student (fp16) | ~36 GB | ä¸»è®­ç»ƒé˜¶æ®µ |
| å•æ¨¡å‹è¯„ä¼° | ä»… Student | ~20 GB | éªŒè¯é˜¶æ®µ |

---

## ğŸ“Š 8. æ¨èç›®å½•ç»“æ„

```
fdistill/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ grpo_data.json
â”‚   â”œâ”€â”€ sft_data.json
â”‚   â””â”€â”€ mixed/
â”‚       â”œâ”€â”€ train_mix.json
â”‚       â””â”€â”€ teacher_outputs.json
â”œâ”€â”€ output/
â”‚   â””â”€â”€ student_kd/
â”œâ”€â”€ generate_teacher_outputs.py
â”œâ”€â”€ run_qwen_kd.sh
â””â”€â”€ README.md
```

---

## ğŸ§© 9. å®éªŒæ€»ç»“

| é˜¶æ®µ | æ¨¡å‹ç»„åˆ | æ¨¡å¼ | ç›®æ ‡ |
|------|------------|--------|--------|
| 1ï¸âƒ£ | Qwen2.5-7B + LoRA | æ¨ç† | ç”Ÿæˆä¼ªæ ‡ç­¾ |
| 2ï¸âƒ£ | Teacher + Qwen1.8B | KL è’¸é¦ | å­¦ä¹  Teacher åˆ†å¸ƒ |
| 3ï¸âƒ£ | Qwen1.8B | è¯„ä¼° | ä¿ç•™ GRPO è¡Œä¸ºä¸é€šç”¨èƒ½åŠ› |

---

## âœ… 10. è¿è¡Œæç¤º

- è‹¥é‡ OOMï¼Œå¯è°ƒå° `batch_size` æˆ–å¢å¤§ `gradient_accumulation_steps`ã€‚  
- è‹¥ Teacher åŠ è½½æ…¢ï¼Œå¯å…ˆæ‰‹åŠ¨ merge LoRA æƒé‡è‡³ base modelã€‚  
- è‹¥ Student æ”¶æ•›æ…¢ï¼Œå¯å°† `alpha` è°ƒä½è‡³ 0.3ï¼Œå¢å¼º CE å­¦ä¹ ã€‚

---

**æœ€ç»ˆè¾“å‡ºè·¯å¾„ï¼š**
```
output/student_kd/
```
å³ä¸ºè’¸é¦å®Œæˆçš„ Qwen1.8B æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡æˆ–æ¨ç†éƒ¨ç½²ã€‚
