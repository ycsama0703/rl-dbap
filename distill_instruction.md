# ğŸ§  Qwen2.5-7B â†’ Qwen1.8B çŸ¥è¯†è’¸é¦å®éªŒ (fdistill æ¡†æ¶)

æœ¬é¡¹ç›®å±•ç¤ºå¦‚ä½•ä½¿ç”¨ [MANGA-UOFA/fdistill](https://github.com/MANGA-UOFA/fdistill) æ¡†æ¶  
å°†ç»è¿‡ **GRPO å¾®è°ƒçš„ Qwen2.5-7B + LoRA** è’¸é¦ä¸ºæ›´è½»é‡çš„ **Qwen1.8B Student** æ¨¡å‹ã€‚  
æµç¨‹é’ˆå¯¹å•å¡ **A100-40GB** ç¯å¢ƒä¼˜åŒ–ï¼ŒåŒ…å«æ•°æ®æ··åˆã€Teacher è¾“å‡ºç”Ÿæˆä¸åœ¨çº¿è’¸é¦è®­ç»ƒã€‚

---

## ğŸ“¦ 1. ç¯å¢ƒå‡†å¤‡

```bash
conda create -n qwen_kd python=3.10 -y
conda activate qwen_kd
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.43.3 peft accelerate datasets bitsandbytes
pip install sentencepiece tqdm nlg-eval
```

---

## ğŸ“‚ 2. è·å– fdistill ä»“åº“

```bash
git clone https://github.com/MANGA-UOFA/fdistill.git
cd fdistill
```

---

## ğŸ§° 3. æ•°æ®å‡†å¤‡ï¼ˆ70% GRPO + 30% SFTï¼‰

ä»“åº“å†…çš„åŸå§‹æ•°æ®å·²ç»æŒ‰å…¬å¸ç±»åˆ«æ‹†åˆ†å­˜æ”¾ï¼š

- GRPOï¼š`artifacts/grpo/grpo_<category>.jsonl`
- SFTï¼š`artifacts/sft/sft_train_<category>.jsonl`
- `<category>` å–å€¼ï¼š`banks`ã€`households`ã€`insurance_companies`ã€`investment_advisors`ã€`mutual_funds`ã€`other`ã€`pension_funds`

è¿è¡Œä¸‹åˆ—è„šæœ¬ï¼Œå°†æ¯ä¸ªå…¬å¸ç±»åˆ«æŒ‰ 70% GRPO + 30% SFT æ··åˆï¼Œè¾“å‡ºåˆ° `artifacts/distill_data/raw/train_mix_<category>.jsonl`ï¼š

```bash
python - <<'PY'
import json
import random
from pathlib import Path

repo_root = Path.cwd()
grpo_dir = repo_root / "artifacts" / "grpo"
sft_dir = repo_root / "artifacts" / "sft"
output_dir = repo_root / "artifacts" / "distill_data" / "raw"
output_dir.mkdir(parents=True, exist_ok=True)

categories = [
    "banks",
    "households",
    "insurance_companies",
    "investment_advisors",
    "mutual_funds",
    "other",
    "pension_funds",
]

def load_jsonl(path: Path):
    with path.open("r", encoding="utf-8") as f:
        return [json.loads(line) for line in f if line.strip()]

random.seed(42)
for cat in categories:
    grpo_path = grpo_dir / f"grpo_{cat}.jsonl"
    sft_path = sft_dir / f"sft_train_{cat}.jsonl"

    if not grpo_path.exists() or not sft_path.exists():
        print(f"[skip] {cat}: missing source file")
        continue

    grpo_records = load_jsonl(grpo_path)
    sft_records = load_jsonl(sft_path)
    if not grpo_records or not sft_records:
        raise RuntimeError(f"{cat}: empty source data")

    grpo_take = min(int(len(grpo_records) * 0.7), len(grpo_records))
    sft_take = min(int(len(sft_records) * 0.3), len(sft_records))

    mix = random.sample(grpo_records, grpo_take) + random.sample(sft_records, sft_take)
    random.shuffle(mix)

    out_path = output_dir / f"train_mix_{cat}.jsonl"
    with out_path.open("w", encoding="utf-8") as f:
        for rec in mix:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

    print(f"[ok] {cat}: {len(mix)} records -> {out_path}")
PY
```

è„šæœ¬æ‰§è¡Œå®Œåï¼Œ`artifacts/distill_data/raw/` ä¸‹å°†ç”Ÿæˆå„å…¬å¸çš„ `train_mix_<category>.jsonl`ï¼Œåç»­æ­¥éª¤ä¼šåŸºäºè¿™äº›æ–‡ä»¶ç”Ÿæˆæ•™å¸ˆä¼ªæ ‡ç­¾å¹¶è½¬æˆæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„ `.source/.target` æ ¼å¼ã€‚

---

## ğŸ§  4. ç”Ÿæˆ Teacher è¾“å‡ºï¼ˆç¦»çº¿ä¼ªæ ‡ç­¾ï¼‰

1. **å¯¼å‡º Prompt**  
   ```bash
   python scripts/export_infer_prompts.py \
     --in artifacts/distill_data/raw/train_mix_banks.jsonl \
     --out-dir artifacts/distill_data/raw \
     --stem banks_teacher
   ```
   `banks` æ¢æˆå…¶å®ƒå…¬å¸å³å¯ã€‚è„šæœ¬ä¼šç”Ÿæˆ `banks_teacher_prompts_base.jsonl`ï¼ˆä¸ `_grpo` å†…å®¹ç›¸åŒï¼Œä¿ç•™ä¸€ä»½å³å¯ï¼‰ã€‚

2. **æ‰¹é‡æ¨ç†**  
   ```bash
   python scripts/batch_infer.py \
     --jsonl artifacts/distill_data/raw/banks_teacher_prompts_base.jsonl \
     --base_model Qwen/Qwen2.5-7B-Instruct \
     --checkpoint outputs/grpo_banks_qwen2p5/v3-20251103-130248/checkpoint-500 \
     --out_jsonl artifacts/distill_data/raw/teacher_outputs_banks.jsonl \
     --batch_size 4 \
     --max_new_tokens 512 \
     --temperature 0.7 \
     --torch_dtype bfloat16
   ```
   - `--base_model` å¯æ¢æˆæœ¬åœ°ç¼“å­˜ç›®å½•ã€‚
   - ç”Ÿæˆçš„ `teacher_outputs_<category>.jsonl` åŒ…å«å®Œæ•´ `<think>/<answer>` æ–‡æœ¬ä»¥åŠè§£æå‡ºçš„ `holding_log_delta`ã€‚

3. **è½¬æ¢ä¸º `.source/.target`**  
   ```bash
   python - <<'PY'
   import json
   from pathlib import Path

   root = Path("artifacts/distill_data")
   raw_dir = root / "raw"
   processed_dir = root / "processed"
   processed_dir.mkdir(parents=True, exist_ok=True)

   categories = [
       "banks",
       "households",
       "insurance_companies",
       "investment_advisors",
       "mutual_funds",
       "other",
       "pension_funds",
   ]

   for cat in categories:
       prompt_path = raw_dir / f"{cat}_teacher_prompts_base.jsonl"
       output_path = raw_dir / f"teacher_outputs_{cat}.jsonl"
       if not prompt_path.exists() or not output_path.exists():
           print(f"[skip] {cat}: missing prompts or teacher outputs")
           continue

       prompts = {}
       with prompt_path.open("r", encoding="utf-8") as f:
           for line in f:
               rec = json.loads(line)
               prompts[rec["id"]] = rec

       generations = []
       with output_path.open("r", encoding="utf-8") as f:
           for line in f:
               generations.append(json.loads(line))

       out_dir = processed_dir / cat
       out_dir.mkdir(parents=True, exist_ok=True)

       with (out_dir / "train.source").open("w", encoding="utf-8") as f_src, \
            (out_dir / "train.target").open("w", encoding="utf-8") as f_tgt:
           for row in sorted(generations, key=lambda x: x["id"]):
               prompt = prompts[row["id"]]
               system = (prompt.get("system") or "").strip()
               user = (prompt.get("prompt") or "").strip()
               teacher = (row.get("raw_output") or "").rstrip()
               f_src.write(f"{system}\n\n{user}\n")
               f_tgt.write(f"{teacher}\n")

       print(f"[ok] wrote {cat}: {len(generations)} samples -> {out_dir}")
   PY
   ```

æœ€ç»ˆï¼Œè’¸é¦è„šæœ¬çš„ `--data_dir` å¯ä»¥ç›´æ¥æŒ‡å‘ `artifacts/distill_data/processed/<category>`ï¼Œå…¶ä¸­åŒ…å« `train.source` / `train.target`ï¼ˆä»¥åŠæŒ‰éœ€æ‰©å±•çš„ `val.*`ã€`test.*`ï¼‰ã€‚

---

## ğŸ”¥ 5. å¯åŠ¨è’¸é¦è®­ç»ƒ (KL Divergence)

```bash
cat > run_qwen_kd.sh <<'SH'
#!/bin/bash
export CUDA_VISIBLE_DEVICES=0

python train_kd.py \
  --teacher_model "<base model path>" \
  --teacher_lora "<checkpoint path>" \
  --student_model "Qwen1.8B" \
  --dataset_path "data/mixed/teacher_outputs.json" \
  --output_dir "./output/student_kd" \
  --temperature 2.0 \
  --alpha 0.5 \
  --num_train_epochs 3 \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --lr 5e-5 \
  --fp16 True \
  --teacher_8bit True \
  --gradient_checkpointing True
SH

bash run_qwen_kd.sh
```

### å‚æ•°è¯´æ˜
| å‚æ•° | å«ä¹‰ | æ¨èå€¼ |
|------|------|--------|
| `temperature` | KL Soft label å¹³æ»‘åº¦ | 2.0 |
| `alpha` | KL ä¸ CE æƒé‡ | 0.5 |
| `batch_size` | å•å¡ batch | 2 |
| `gradient_accumulation_steps` | ç´¯ç§¯æ­¥æ•° | 8 |
| `lr` | å­¦ä¹ ç‡ | 5e-5 |
| `num_train_epochs` | è®­ç»ƒè½®æ•° | 3 |

é¢„è®¡æ˜¾å­˜å ç”¨ï¼š**çº¦ 36â€“38 GB (fp16)**ã€‚

---

## ğŸ“ˆ 6. æ¨¡å‹è¯„ä¼°

```bash
python eval_model.py \
  --model_path ./output/student_kd \
  --data_path data/val.json \
  --metrics bleu rouge ppl
```

æˆ–ä½¿ç”¨ nlg-eval:
```bash
nlg-eval --hypothesis=student_output.txt --references=ref.txt
```

---

## ğŸ’¾ 7. æ˜¾å­˜å ç”¨å‚è€ƒ (A100-40GB)

| æ¨¡å¼ | è¯´æ˜ | æ˜¾å­˜ | å¤‡æ³¨ |
|------|------|------|------|
| ç”Ÿæˆä¼ªæ ‡ç­¾ | ä»… Teacher (8bit) | ~18 GB | ç¦»çº¿ç”Ÿæˆ |
| åœ¨çº¿è’¸é¦ | Teacher + Student (fp16) | ~36 GB | ä¸»è®­ç»ƒé˜¶æ®µ |
| å•æ¨¡å‹è¯„ä¼° | ä»… Student | ~20 GB | éªŒè¯é˜¶æ®µ |

---

## ğŸ“Š 8. æ¨èç›®å½•ç»“æ„

```
fdistill/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ grpo_data.json
â”‚   â”œâ”€â”€ sft_data.json
â”‚   â””â”€â”€ mixed/
â”‚       â”œâ”€â”€ train_mix.json
â”‚       â””â”€â”€ teacher_outputs.json
â”œâ”€â”€ output/
â”‚   â””â”€â”€ student_kd/
â”œâ”€â”€ generate_teacher_outputs.py
â”œâ”€â”€ run_qwen_kd.sh
â””â”€â”€ README.md
```

---

## ğŸ§© 9. å®éªŒæ€»ç»“

| é˜¶æ®µ | æ¨¡å‹ç»„åˆ | æ¨¡å¼ | ç›®æ ‡ |
|------|------------|--------|--------|
| 1ï¸âƒ£ | Qwen2.5-7B + LoRA | æ¨ç† | ç”Ÿæˆä¼ªæ ‡ç­¾ |
| 2ï¸âƒ£ | Teacher + Qwen1.8B | KL è’¸é¦ | å­¦ä¹  Teacher åˆ†å¸ƒ |
| 3ï¸âƒ£ | Qwen1.8B | è¯„ä¼° | ä¿ç•™ GRPO è¡Œä¸ºä¸é€šç”¨èƒ½åŠ› |

---

## âœ… 10. è¿è¡Œæç¤º

- è‹¥é‡ OOMï¼Œå¯è°ƒå° `batch_size` æˆ–å¢å¤§ `gradient_accumulation_steps`ã€‚  
- è‹¥ Teacher åŠ è½½æ…¢ï¼Œå¯å…ˆæ‰‹åŠ¨ merge LoRA æƒé‡è‡³ base modelã€‚  
- è‹¥ Student æ”¶æ•›æ…¢ï¼Œå¯å°† `alpha` è°ƒä½è‡³ 0.3ï¼Œå¢å¼º CE å­¦ä¹ ã€‚

---

**æœ€ç»ˆè¾“å‡ºè·¯å¾„ï¼š**
```
output/student_kd/
```
å³ä¸ºè’¸é¦å®Œæˆçš„ Qwen1.8B æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡æˆ–æ¨ç†éƒ¨ç½²ã€‚
