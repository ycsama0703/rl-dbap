import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from pathlib import Path
import numpy as np

# === è·¯å¾„ ===
metrics_dir = Path("output/distill_eval_output")
print(f"âœ… Using metrics directory: {metrics_dir}")

metrics_files = sorted(metrics_dir.glob("metrics_from_*.csv"))
if not metrics_files:
    raise RuntimeError(f"âŒ No metrics_from_*.csv found in {metrics_dir}")

print(f"âœ… Found {len(metrics_files)} metric files")

dfs = []
for f in metrics_files:
    try:
        df = pd.read_csv(f)
        df["source_file"] = f.name
        dfs.append(df)
    except Exception as e:
        print(f"âš ï¸ Failed to read {f.name}: {e}")

if not dfs:
    raise RuntimeError("âŒ No valid CSVs loaded.")

df_all = pd.concat(dfs, ignore_index=True)
df_all.columns = [c.strip() for c in df_all.columns]

# === æå–æ¨¡å‹åä¸ trim ===
df_all["model"] = df_all["source_file"].str.extract(r"metrics_from_debug_eval_([^.]*)")[0]
df_all["trim"] = df_all["source_file"].apply(
    lambda x: "99" if "trim99" in x else ("95" if "trim95" in x else "all")
)

# === æŒ‡æ ‡ï¼šå»æ‰ IC ä¸ RankIC ===
metrics = [
    "MAE_log", "RMSE_log", "R2_log",
    "sMAPE_log%", "coverage_valid%", "coverage_filtered%"
]
available_metrics = [m for m in metrics if m in df_all.columns]
print(f"ğŸ“Š Metrics available: {available_metrics}")

# === èšåˆ ===
agg = df_all.groupby(["model", "trim"])[available_metrics].mean().reset_index()

# === å…¨å±€é¢œè‰²æ˜ å°„ï¼ˆæ¯ç§æ¨¡å‹å›ºå®šé¢œè‰²ï¼‰ ===
model_list = sorted(agg["model"].unique())
n_models = len(model_list)
colors = cm.get_cmap("tab10", n_models)
color_map = {model: colors(i) for i, model in enumerate(model_list)}

# === trim é¡ºåº ===
trim_levels = ["all", "95", "99"]

# === ç»˜åˆ¶æ¯ä¸ª trim çš„ 2x3 é¢æ¿ ===
for trim in trim_levels:
    sub = agg[agg["trim"] == trim]
    if sub.empty:
        continue

    sub_models = sorted(sub["model"].unique())
    n_sub_models = len(sub_models)
    colors_used = [color_map[m] for m in sub_models]

    n_metrics = len(available_metrics)
    fig, axes = plt.subplots(2, 3, figsize=(16, 6))
    fig.suptitle(f"Model Comparison â€” Trim {trim}", fontsize=16, y=1.02)

    for i, metric in enumerate(available_metrics):
        ax = axes[i // 3, i % 3]
        x = np.arange(n_sub_models)
        vals = [sub[sub["model"] == m][metric].values[0] for m in sub_models]

        # å…³é”®ï¼šè®©æŸ±çŠ¶å›¾å˜â€œç»†é•¿â€
        bar_width = 0.4 / max(1, n_sub_models / 6)
        bars = ax.bar(x, vals, color=colors_used, width=bar_width)

        ax.set_title(metric, fontsize=11)
        ax.set_xticks(x)
        ax.set_xticklabels(sub_models, rotation=30, ha="right", fontsize=8)
        ax.grid(axis="y", alpha=0.3)

        # æ•°å€¼æ ‡ç­¾
        for xi, yi in zip(x, vals):
            ax.text(xi, yi, f"{yi:.3f}", ha="center", va="bottom", fontsize=7)

    # ç§»é™¤å¤šä½™ç©ºè½´ï¼ˆè‹¥æŒ‡æ ‡ä¸æ˜¯6ä¸ªï¼‰
    for j in range(n_metrics, 6):
        fig.delaxes(axes[j // 3, j % 3])

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    out_path = metrics_dir / f"metrics_panel_trim{trim}_2x3.png"
    plt.savefig(out_path, dpi=300, bbox_inches="tight")
    plt.close(fig)
    print(f"âœ… Saved {out_path}")

print("ğŸ¯ Done! Each trim-level has a 2x3 grid with slim vertical bars.")
